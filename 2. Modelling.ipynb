{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main source: Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "# secondary source: https://gist.github.com/aniruddha27/eaf96b6ce2a98eb8cded822d01493a70#file-auc-roc6-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in data\n",
    "\n",
    "df_rp = pd.read_csv(\"Desktop/Feature extraction/df_regionprops.csv\")\n",
    "df_surv_2 = pd.read_csv('Desktop/Feature extraction/with less features/df_surv_2.csv')\n",
    "df_surv_3 = pd.read_csv('Desktop/Feature extraction/with less features/df_surv_3.csv')\n",
    "df_all = pd.read_csv('Desktop/Feature extraction/with less features/df_all.csv')\n",
    "df_all = df_all.drop([\"Unnamed: 0\"], axis = 1)\n",
    "df_all['Survival_group'] = df_surv_2.iloc[:,5] #switch between 2-class survival and 3-class survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating 3 feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Creating full radiomics feature set\n",
    "\n",
    "df_radiomics= df_all.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Creating shape and volume feature set\n",
    "\n",
    "df_2 = pd.concat([df_all, df_rp], axis = 1, join = \"inner\")\n",
    "\n",
    "df_2.drop(df_2.columns[df_2.columns.str.contains('original_glcm')], axis=1, inplace=True)\n",
    "df_sha_vol = df_2.drop(['centroid_0_ncrnet', 'centroid_0_ed', 'centroid_0_et',\n",
    "       'centroid_1_ncrnet', 'centroid_1_ed', 'centroid_1_et',\n",
    "       'centroid_2_ncrnet', 'centroid_2_ed', 'centroid_2_et', 'area_ncrnet',\n",
    "       'area_ed', 'area_et', 'major_axis_length_ncrnet',\n",
    "       'major_axis_length_ed', 'major_axis_length_et',\n",
    "       'minor_axis_length_ncrnet', 'minor_axis_length_ed',\n",
    "       'minor_axis_length_et', 'Unnamed: 0','original_firstorder_10Percentile_ed', \n",
    "       'original_firstorder_90Percentile_ed', 'original_firstorder_Energy_ed', 'original_firstorder_Entropy_ed',\n",
    "       'original_firstorder_InterquartileRange_ed', 'original_firstorder_Kurtosis_ed',\n",
    "       'original_firstorder_Maximum_ed', 'original_firstorder_MeanAbsoluteDeviation_ed',\n",
    "       'original_firstorder_Mean_ed', 'original_firstorder_Median_ed', 'original_firstorder_Minimum_ed',\n",
    "       'original_firstorder_Range_ed', 'original_firstorder_RobustMeanAbsoluteDeviation_ed',\n",
    "       'original_firstorder_RootMeanSquared_ed', 'original_firstorder_Skewness_ed',\n",
    "       'original_firstorder_TotalEnergy_ed', 'original_firstorder_Uniformity_ed', \n",
    "       'original_firstorder_Variance_ed','original_firstorder_10Percentile_ncrnet',\n",
    "       'original_firstorder_90Percentile_ncrnet', 'original_firstorder_Energy_ncrnet', 'original_firstorder_Entropy_ncrnet',\n",
    "       'original_firstorder_InterquartileRange_ncrnet', 'original_firstorder_Kurtosis_ncrnet', 'original_firstorder_Maximum_ncrnet',\n",
    "       'original_firstorder_MeanAbsoluteDeviation_ncrnet', 'original_firstorder_Mean_ncrnet', 'original_firstorder_Median_ncrnet',\n",
    "       'original_firstorder_Minimum_ncrnet', 'original_firstorder_Range_ncrnet', 'original_firstorder_RobustMeanAbsoluteDeviation_ncrnet',\n",
    "       'original_firstorder_RootMeanSquared_ncrnet', 'original_firstorder_Skewness_ncrnet', 'original_firstorder_TotalEnergy_ncrnet', \n",
    "       'original_firstorder_Uniformity_ncrnet', 'original_firstorder_Variance_ncrnet',\n",
    "       'original_firstorder_10Percentile_et', \n",
    "       'original_firstorder_90Percentile_et', 'original_firstorder_Energy_et', 'original_firstorder_Entropy_et',\n",
    "       'original_firstorder_InterquartileRange_et', 'original_firstorder_Kurtosis_et',\n",
    "       'original_firstorder_Maximum_et', 'original_firstorder_MeanAbsoluteDeviation_et',\n",
    "       'original_firstorder_Mean_et', 'original_firstorder_Median_et', 'original_firstorder_Minimum_et',\n",
    "       'original_firstorder_Range_et', 'original_firstorder_RobustMeanAbsoluteDeviation_et',\n",
    "       'original_firstorder_RootMeanSquared_et', 'original_firstorder_Skewness_et',\n",
    "       'original_firstorder_TotalEnergy_et', 'original_firstorder_Uniformity_et', \n",
    "       'original_firstorder_Variance_et'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Creating handcrafted model (regionprops)\n",
    "\n",
    "df_handcrafted = df_2.copy()\n",
    "df_handcrafted.drop(df_handcrafted.columns[df_handcrafted.columns.str.contains('original_')], axis=1, inplace=True)\n",
    "df_handcrafted = df_handcrafted.drop(['Unnamed: 0'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 'NA' group in 'Extent_of_Resection' column and use it as group\n",
    "\n",
    "df_radiomics.Extent_of_Resection = df_radiomics.Extent_of_Resection.fillna(\"NA\")\n",
    "df_sha_vol.Extent_of_Resection = df_sha_vol.Extent_of_Resection.fillna(\"NA\")\n",
    "df_handcrafted.Extent_of_Resection = df_handcrafted.Extent_of_Resection.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split, normalization and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Extent_of_Resection\n",
    "\n",
    "df_radiomics_enc = pd.get_dummies(df_radiomics['Extent_of_Resection'])\n",
    "df_radiomics = pd.concat([df_radiomics, df_radiomics_enc], axis = 1).drop(['Extent_of_Resection'], axis=1)\n",
    "\n",
    "df_sha_vol_enc = pd.get_dummies(df_sha_vol['Extent_of_Resection'])\n",
    "df_sha_vol = pd.concat([df_sha_vol, df_sha_vol_enc], axis = 1).drop(['Extent_of_Resection'], axis=1)\n",
    "\n",
    "df_handcrafted_enc = pd.get_dummies(df_handcrafted['Extent_of_Resection'])\n",
    "df_handcrafted = pd.concat([df_handcrafted, df_handcrafted_enc], axis = 1).drop(['Extent_of_Resection'], axis=1)\n",
    "\n",
    "#re-arrange order of columns\n",
    "\n",
    "cols = df_radiomics.columns.tolist()\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "df_radiomics = df_radiomics[cols]\n",
    "\n",
    "cols = df_sha_vol.columns.tolist()\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "df_sha_vol = df_sha_vol[cols]\n",
    "\n",
    "cols = df_handcrafted.columns.tolist()\n",
    "cols = cols[-3:] + cols[:-3]\n",
    "df_handcrafted = df_handcrafted[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE-reduced feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-class RFE-reduced radiomics set --> 23 features\n",
    "\n",
    "# df_radiomics_rfe2 = df_radiomics.copy()\n",
    "# df_radiomics_rfe2 = df_radiomics_rfe2[['NA', 'STR', 'Age', 'original_shape_Elongation_ncrnet',\n",
    "#        'original_shape_Maximum2DDiameterRow_ncrnet',\n",
    "#        'original_shape_Maximum3DDiameter_ncrnet',\n",
    "#        'original_shape_SurfaceArea_ncrnet',\n",
    "#        'original_shape_VoxelVolume_ncrnet',\n",
    "#        'original_firstorder_Maximum_ncrnet', 'original_glcm_Contrast_ncrnet',\n",
    "#        'original_glcm_DifferenceAverage_ncrnet',\n",
    "#        'original_shape_MajorAxisLength_ed',\n",
    "#        'original_shape_Maximum2DDiameterColumn_ed',\n",
    "#        'original_shape_MinorAxisLength_ed', 'original_shape_SurfaceArea_ed',\n",
    "#        'original_shape_SurfaceVolumeRatio_ed',\n",
    "#        'original_firstorder_Maximum_ed', 'original_firstorder_Mean_ed',\n",
    "#        'original_firstorder_Variance_ed', 'original_shape_LeastAxisLength_et',\n",
    "#        'original_shape_MajorAxisLength_et',\n",
    "#        'original_shape_Maximum2DDiameterRow_et',\n",
    "#        'original_shape_Maximum2DDiameterSlice_et',\n",
    "#        'original_shape_MeshVolume_et', 'original_shape_SurfaceArea_et',\n",
    "#        'original_shape_SurfaceVolumeRatio_et',\n",
    "#        'original_shape_VoxelVolume_et']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-class RFE-reduced shape & volume set --> 38 features \n",
    "\n",
    "# df_sha_vol_rfe2 = df_sha_vol.copy()\n",
    "# df_sha_vol_rfe2 = df_sha_vol_rfe2[['GTR', 'NA', 'Age', 'original_shape_Elongation_ncrnet',\n",
    "# 'original_shape_Flatness_ncrnet','original_shape_LeastAxisLength_ncrnet',\n",
    "#       'original_shape_Maximum2DDiameterColumn_ncrnet',\n",
    "#        'original_shape_Maximum2DDiameterRow_ncrnet',\n",
    "#        'original_shape_Maximum2DDiameterSlice_ncrnet',\n",
    "#        'original_shape_Maximum3DDiameter_ncrnet',\n",
    "#        'original_shape_SurfaceArea_ncrnet',\n",
    "#        'original_shape_SurfaceVolumeRatio_ncrnet',\n",
    "#        'original_shape_VoxelVolume_ncrnet', 'original_shape_Elongation_ed',\n",
    "#        'original_shape_Flatness_ed', 'original_shape_LeastAxisLength_ed',\n",
    "#        'original_shape_MajorAxisLength_ed',\n",
    "#        'original_shape_Maximum2DDiameterColumn_ed',\n",
    "#        'original_shape_Maximum2DDiameterRow_ed',\n",
    "#        'original_shape_Maximum2DDiameterSlice_ed',\n",
    "#        'original_shape_Maximum3DDiameter_ed', 'original_shape_MeshVolume_ed',\n",
    "#        'original_shape_MinorAxisLength_ed', 'original_shape_SurfaceArea_ed',\n",
    "#        'original_shape_SurfaceVolumeRatio_ed', 'original_shape_VoxelVolume_ed',\n",
    "#        'original_shape_Elongation_et', 'original_shape_LeastAxisLength_et',\n",
    "#        'original_shape_MajorAxisLength_et',\n",
    "#        'original_shape_Maximum2DDiameterColumn_et',\n",
    "#        'original_shape_Maximum2DDiameterRow_et',\n",
    "#        'original_shape_Maximum2DDiameterSlice_et',\n",
    "#        'original_shape_Maximum3DDiameter_et', 'original_shape_MeshVolume_et',\n",
    "#        'original_shape_MinorAxisLength_et', 'original_shape_SurfaceArea_et',\n",
    "#        'original_shape_SurfaceVolumeRatio_et',\n",
    "#        'original_shape_VoxelVolume_et']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-class RFE-reduced handcrafted set --> 9 features \n",
    "\n",
    "# df_handcrafted_rfe2 = df_handcrafted.copy()\n",
    "# df_handcrafted_rfe2 = df_handcrafted_rfe2[['STR', 'Age', 'centroid_0_ncrnet', 'centroid_0_et', 'centroid_2_ed',\n",
    "#        'centroid_2_et', 'area_ed', 'major_axis_length_ncrnet',\n",
    "#        'minor_axis_length_ed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-class RFE-reduced radiomics set --> 3 features\n",
    "\n",
    "# df_radiomics_rfe = df_radiomics.copy()\n",
    "# df_radiomics_rfe = df_radiomics_rfe[[\"Age\", \"STR\", \"original_shape_LeastAxisLength_ed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3-class RFE-reduced shape and volume set --> 8 features \n",
    "\n",
    "# df_sha_vol_rfe = df_sha_vol.copy()\n",
    "# df_sha_vol_rfe = df_sha_vol_rfe[['STR', 'Age', 'original_shape_Maximum3DDiameter_ncrnet',\n",
    "#        'original_shape_LeastAxisLength_ed',\n",
    "#        'original_shape_Maximum2DDiameterSlice_et',\n",
    "#        'original_shape_MeshVolume_et', 'original_shape_SurfaceArea_et',\n",
    "#        'original_shape_SurfaceVolumeRatio_et']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-class RFE-reduced handcrafted set --> 4 features ('GTR', 'STR', 'Age', 'minor_axis_length_ed')\n",
    "\n",
    "# df_handcrafted_rfe = df_handcrafted.copy()\n",
    "# df_handcrafted_rfe = df_handcrafted_rfe[['GTR', 'STR', 'Age', 'minor_axis_length_ed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize X and y datasets\n",
    "\n",
    "df_X = df_radiomics.copy()\n",
    "df_X = df_X.drop(['Brats20ID', 'Survival_days', 'Survival_group'], axis = 1)\n",
    "\n",
    "df_y = df_radiomics.copy()\n",
    "df_y = df_y.iloc[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "\n",
    "X = df_X\n",
    "y = df_y\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncode the target variable (3 classes) or (2 classes)\n",
    "#0 = long-term   #0 = long-term\n",
    "#1 = mid-term    #1 = short-term\n",
    "#2 = short-term\n",
    "\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc\n",
    "\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: binarize the target variable for multiclass AUROC values\n",
    "\n",
    "# y_train_bi = label_binarize(y_train, classes=['short-term','mid-term','long-term'])\n",
    "# n_classes = y_train_bi.shape[1]\n",
    "\n",
    "# y_test_bi = label_binarize(y_test, classes=['short-term', 'mid-term','long-term'])\n",
    "# n_classes = y_test_bi.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize portions of dataset for StandardScaler\n",
    "\n",
    "X_train_scaler = X_train.iloc[:,1:]\n",
    "X_test_scaler = X_test.iloc[:,1:]\n",
    "\n",
    "X_train_rest = X_train.iloc[:,:1]\n",
    "X_test_rest = X_test.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use StandardScaler and recombine non-scaled data with scaled data\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_st = pd.DataFrame(scaler.fit_transform(X_train_scaler),index=X_train_scaler.index)\n",
    "X_test_st = pd.DataFrame(scaler.transform(X_test_scaler), index=X_test_scaler.index)\n",
    "\n",
    "X_train_st = pd.DataFrame(data=X_train_st.values, columns=X_train_scaler.columns, index=X_train_scaler.index)\n",
    "X_test_st = pd.DataFrame(data=X_test_st.values, columns=X_test_scaler.columns, index=X_test_scaler.index)\n",
    "\n",
    "\n",
    "X_train_final = pd.concat([X_train_rest, X_train_st], axis = 1, join = \"inner\")\n",
    "X_test_final = pd.concat([X_test_rest, X_test_st], axis = 1, join = \"inner\")\n",
    "\n",
    "\n",
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of labels in train and test data\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.title(\"Training survival group distribution\")\n",
    "sns.countplot(x=y_train, order=('short-term','long-term'))\n",
    "plt.savefig('Training survival group distribution 2-class.png', facecolor = 'w')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Testing survival group distribution\")\n",
    "sns.countplot(x=y_test, order=('short-term','long-term'))\n",
    "plt.savefig('Testing survival group distribution 2-class.png', facecolor = 'w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RFE-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "min_features_to_select=1\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=10,\n",
    "              scoring='accuracy',\n",
    "              min_features_to_select=1)\n",
    "\n",
    "rfecv.fit(X_train_final, y_train_enc)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "print(\"Ranking of features:\", rfecv.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of features versus cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.xlim(0,80)\n",
    "plt.xticks(np.arange(0, 80, 5))\n",
    "plt.ylabel(\"Cross validation accuracy\")\n",
    "plt.plot(range(min_features_to_select,\n",
    "               len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "# plt.savefig('RFE_SVM plot.png', facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfecv.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfecv.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('coefficients',rfecv.estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features to select:\",X_train_final.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset with ALL features combined for feature importance\n",
    "\n",
    "df_cor_all = df_radiomics.copy()\n",
    "df_cor_all = pd.concat([df_cor_all, df_rp], axis=1, join='inner')\n",
    "df_cor_all = df_cor_all.drop(['Brats20ID', 'Survival_group'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_cor_all.corr(method = 'spearman')\n",
    "cor_all = corr_matrix[\"Survival_days\"].sort_values(ascending=True)\n",
    "\n",
    "print(cor_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Spearman's correlation to rank feature importances\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "r_cor = spearmanr(df_cor_all)\n",
    "r_cor_list = list(r_cor)\n",
    "\n",
    "display(r_cor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_radiomics.corr(method = 'spearman')\n",
    "# print(corr_matrix[\"Survival_days\"].sort_values(ascending=True))\n",
    "\n",
    "corr_list = dict(corr_matrix[\"Survival_days\"].sort_values(ascending=True))\n",
    "\n",
    "print(corr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#majority class classifier as baseline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_clf.fit(X_train_final, y_train_enc)\n",
    "dummy_clf.predict(X_test_final)\n",
    "result = dummy_clf.score(X_test_final, y_test_enc)\n",
    "print(\"The classification accuracy of a new data point =\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification ROC_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "n_classes = y_train_bi.shape[1]\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__n_neighbors': np.arange(1,144,1),\n",
    "}\n",
    "\n",
    "knn = OneVsRestClassifier(KNeighborsClassifier())\n",
    "\n",
    "knn_clf = GridSearchCV(\n",
    "        knn, param_grid, cv = 10, scoring='roc_auc')\n",
    "\n",
    "knn_y_score = knn_clf.fit(X_train_final_rfe_rad, y_train_bi).predict_proba(X_test_final_rfe_rad)\n",
    "y_true, y_pred = y_test_bi, knn_clf.predict(X_test_final_rfe_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "knn_fpr = dict()\n",
    "knn_tpr = dict()\n",
    "knn_roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    knn_fpr[i], knn_tpr[i], _ = roc_curve(y_test_bi[:, i], knn_y_score[:, i])\n",
    "    knn_roc_auc[i] = auc(knn_fpr[i], knn_tpr[i])\n",
    "    \n",
    "\n",
    "knn_mean_roc = roc_auc_score(y_true, knn_clf.predict_proba(X_test_final_rfe_rad), multi_class='ovr')\n",
    "knn_mean_roc_micro = roc_auc_score(y_true, knn_clf.predict_proba(X_test_final_rfe_rad), multi_class='ovr', average = 'micro')\n",
    "\n",
    "print(\"Dictionary of ROC_AUC score per class:\")\n",
    "print(knn_roc_auc)\n",
    "print(\"ROC_AUC score over all three labels [Macro-averaging]:\")\n",
    "print(knn_mean_roc)\n",
    "print(\"ROC_AUC score over all three labels with unbalanced classes taken into account [Micro-averaging]: \")\n",
    "print(knn_mean_roc_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing macro averaging for plotting\n",
    "import numpy as np\n",
    "\n",
    "knn_all_fpr = np.unique(np.concatenate([knn_fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "knn_mean_tpr = np.zeros_like(knn_all_fpr)\n",
    "for i in range(n_classes):\n",
    "    knn_mean_tpr += np.interp(knn_all_fpr, knn_fpr[i], knn_tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "knn_mean_tpr /= n_classes\n",
    "\n",
    "knn_fpr[\"macro\"] = knn_all_fpr\n",
    "knn_tpr[\"macro\"] = knn_mean_tpr\n",
    "knn_roc_auc[\"macro\"] = auc(knn_fpr[\"macro\"], knn_tpr[\"macro\"])\n",
    "\n",
    "print(knn_roc_auc['macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing micro averaging for plotting\n",
    "\n",
    "knn_fpr[\"micro\"], knn_tpr[\"micro\"], _ = roc_curve(y_test_bi.ravel(), knn_y_score.ravel())\n",
    "knn_roc_auc[\"micro\"] = auc(knn_fpr[\"micro\"], knn_tpr[\"micro\"])\n",
    "\n",
    "print(knn_roc_auc['micro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://gist.github.com/aniruddha27/eaf96b6ce2a98eb8cded822d01493a70#file-auc-roc6-py\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(knn_fpr[0], knn_tpr[0], linestyle='-',color='black', label='Long-term ROC curve')\n",
    "plt.plot(knn_fpr[1], knn_tpr[1], linestyle='-',color='black', label='Mid-term ROC curve')\n",
    "plt.plot(knn_fpr[2], knn_tpr[2], linestyle='-',color='black', label='Short-term ROC curve')\n",
    "plt.plot(knn_fpr['micro'], knn_tpr['micro'], linestyle='-',color='red', label='Micro avg ROC curve' )\n",
    "plt.plot(knn_fpr['macro'], knn_tpr['macro'], linestyle = '-', color = 'brown', label='Macro avg ROC curve')\n",
    "plt.title('ROC curve k-NN short-term survivor')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.plot(ident,ident, color='green', linewidth = 2)\n",
    "# plt.savefig('ROC curve k-NN long-term survivor.png',dpi=300, facecolor = 'w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "param_grid = {'estimator__kernel': ['linear','rbf','poly','sigmoid'],\n",
    "              'estimator__gamma': [1, 0.1, 0.01,0.001],\n",
    "              'estimator__C': [0.1, 1, 10, 100]}\n",
    "    \n",
    "svc = OneVsRestClassifier(SVC(kernel='linear', probability=True,\n",
    "                                 random_state=42))\n",
    "\n",
    "\n",
    "svc_clf = GridSearchCV(svc, param_grid, cv = 10, scoring='roc_auc')\n",
    "\n",
    "svc_y_score = svc_clf.fit(X_train_final, y_train_bi).decision_function(X_test_final)\n",
    "y_true, y_pred = y_test_bi, svc_clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "svc_fpr = dict()\n",
    "svc_tpr = dict()\n",
    "svc_roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    svc_fpr[i], svc_tpr[i], _ = roc_curve(y_test_bi[:, i], svc_y_score[:, i])\n",
    "    svc_roc_auc[i] = auc(svc_fpr[i], svc_tpr[i])\n",
    "\n",
    "svc_mean_roc = roc_auc_score(y_true, svc_clf.decision_function(X_test_final), multi_class='ovr')\n",
    "svc_mean_roc_micro = roc_auc_score(y_true, svc_clf.decision_function(X_test_final), multi_class='ovr', average = 'micro')\n",
    "\n",
    "print(\"Dictionary of ROC_AUC score per class:\")\n",
    "print(svc_roc_auc)\n",
    "print(\"ROC_AUC score over all three labels [Macro-averaging]:\")\n",
    "print(svc_mean_roc)\n",
    "print(\"ROC_AUC score over all three labels with unbalanced classes taken into account [Micro-averaging]: \")\n",
    "print(svc_mean_roc_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing macro averaging for plotting\n",
    "import numpy as np\n",
    "\n",
    "svc_all_fpr = np.unique(np.concatenate([svc_fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "svc_mean_tpr = np.zeros_like(svc_all_fpr)\n",
    "for i in range(n_classes):\n",
    "    svc_mean_tpr += np.interp(svc_all_fpr, svc_fpr[i], svc_tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "svc_mean_tpr /= n_classes\n",
    "\n",
    "svc_fpr[\"macro\"] = svc_all_fpr\n",
    "svc_tpr[\"macro\"] = svc_mean_tpr\n",
    "svc_roc_auc[\"macro\"] = auc(svc_fpr[\"macro\"], svc_tpr[\"macro\"])\n",
    "\n",
    "print(svc_roc_auc[\"macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing micro averaging for plotting\n",
    "\n",
    "svc_fpr[\"micro\"], svc_tpr[\"micro\"], _ = roc_curve(y_test_bi.ravel(), svc_y_score.ravel())\n",
    "svc_roc_auc[\"micro\"] = auc(svc_fpr[\"micro\"], svc_tpr[\"micro\"])\n",
    "\n",
    "print(svc_roc_auc[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://gist.github.com/aniruddha27/eaf96b6ce2a98eb8cded822d01493a70#file-auc-roc6-py\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.plot(svc_fpr[0], svc_tpr[0], linestyle='-',color='black', label='Long-term ROC curve')\n",
    "plt.plot(svc_fpr[1], svc_tpr[1], linestyle='-',color='black', label='Mid-term ROC curve')\n",
    "plt.plot(svc_fpr[2], svc_tpr[2], linestyle='-',color='black', label='Short-term ROC curve')\n",
    "plt.plot(svc_fpr['micro'], svc_tpr['micro'], linestyle='-',color='red', label='Micro avg ROC curve' )\n",
    "plt.plot(svc_fpr['macro'], svc_tpr['macro'], linestyle = '-', color = 'brown', label='Macro avg ROC curve')\n",
    "plt.title('ROC curve SVC long-term survivor')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "# plt.savefig('ROC curve SVC long-term survivor.png',dpi=300, facecolor = 'w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "param_grid={'estimator__n_estimators': [30,50,100,200], #100,200,300,400,500\n",
    "            'estimator__max_features': ['auto'],\n",
    "            'estimator__max_depth': [4], #Tuning #2,3,4\n",
    "            'estimator__min_samples_split': [2],#2,3,5\n",
    "            'estimator__min_samples_leaf':[2],#1,2,5\n",
    "            'estimator__criterion': ['entropy']}#entropy\n",
    "\n",
    "\n",
    "rfc = OneVsRestClassifier(RandomForestClassifier(verbose = 2, n_jobs= -1, random_state=42))\n",
    "\n",
    "\n",
    "rfc_clf = GridSearchCV(\n",
    "        rfc, param_grid, cv = 10, scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "rfc_y_score = rfc_clf.fit(X_train_final, y_train_bi).predict_proba(X_test_final)\n",
    "y_true, y_pred = y_test_bi, rfc_clf.predict(X_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "rfc_fpr = dict()\n",
    "rfc_tpr = dict()\n",
    "rfc_roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    rfc_fpr[i], rfc_tpr[i], _ = roc_curve(y_test_bi[:, i], rfc_y_score[:, i])\n",
    "    rfc_roc_auc[i] = auc(rfc_fpr[i], rfc_tpr[i])\n",
    "    \n",
    "rfc_mean_roc = roc_auc_score(y_true, rfc_clf.predict_proba(X_test_final), multi_class='ovr')\n",
    "rfc_mean_roc_micro = roc_auc_score(y_true, rfc_clf.predict_proba(X_test_final), multi_class='ovr', average = 'micro')\n",
    "\n",
    "print(\"Dictionary of ROC_AUC score per class:\")\n",
    "print(rfc_roc_auc)\n",
    "print(\"ROC_AUC score over all three labels [Macro-averaging]:\")\n",
    "print(rfc_mean_roc)\n",
    "print(\"ROC_AUC score over all three labels with unbalanced classes taken into account [Micro-averaging]: \")\n",
    "print(rfc_mean_roc_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing macro averaging for plotting\n",
    "import numpy as np\n",
    "\n",
    "rfc_all_fpr = np.unique(np.concatenate([rfc_fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "rfc_mean_tpr = np.zeros_like(rfc_all_fpr)\n",
    "for i in range(n_classes):\n",
    "    rfc_mean_tpr += np.interp(rfc_all_fpr, rfc_fpr[i], rfc_tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "rfc_mean_tpr /= n_classes\n",
    "\n",
    "rfc_fpr[\"macro\"] = rfc_all_fpr\n",
    "rfc_tpr[\"macro\"] = rfc_mean_tpr\n",
    "rfc_roc_auc[\"macro\"] = auc(rfc_fpr[\"macro\"], rfc_tpr[\"macro\"])\n",
    "\n",
    "print(rfc_roc_auc[\"macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing micro averaging for plotting\n",
    "\n",
    "rfc_fpr[\"micro\"], rfc_tpr[\"micro\"], _ = roc_curve(y_test_bi.ravel(), rfc_y_score.ravel())\n",
    "rfc_roc_auc[\"micro\"] = auc(rfc_fpr[\"micro\"], rfc_tpr[\"micro\"])\n",
    "\n",
    "print(rfc_roc_auc[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://gist.github.com/aniruddha27/eaf96b6ce2a98eb8cded822d01493a70#file-auc-roc6-py\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(rfc_fpr[0], rfc_tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "plt.plot(rfc_fpr[1], rfc_tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "plt.plot(rfc_fpr[2], rfc_tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
    "plt.plot(rfc_fpr[\"micro\"], rfc_tpr[\"micro\"], linestyle='-',color='red', label='Micro avg ROC curve')\n",
    "plt.plot(rfc_fpr[\"macro\"], rfc_tpr[\"macro\"], linestyle='-',color='brown', label='Macro avg ROC curve' )\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# plt.savefig('Multiclass ROC',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBC ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "param_grid={'estimator__n_estimators':[2],\n",
    "            'estimator__max_depth':[2], \n",
    "            'estimator__min_samples_split':[0.1],\n",
    "            'estimator__min_samples_leaf':[0.1],\n",
    "            'estimator__max_features':[1,2,3], #89\n",
    "            'estimator__subsample':[1.0],\n",
    "            'estimator__learning_rate':[0.05]}\n",
    "\n",
    "# grid['n_estimators'] = [10, 50, 100, 500]\n",
    "# grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "# grid['subsample'] = [0.5, 0.7, 1.0]\n",
    "# grid['max_depth'] = [3, 7, 9]\n",
    "\n",
    "#optimally tuned parameters\n",
    "# param_grid={'n_estimators':[100], 'max_depth':[4], 'min_samples_split':[2],\n",
    "#            'min_samples_leaf':[10],'max_features':[7],'subsample':[1],'learning_rate':[0.005]}\n",
    "\n",
    "\n",
    "gbc = OneVsRestClassifier(GradientBoostingClassifier(\n",
    "                                 random_state=42))\n",
    "\n",
    "\n",
    "gbc_clf = GridSearchCV(gbc, param_grid, cv = 10, scoring='roc_auc')\n",
    "\n",
    "gbc_y_score = gbc_clf.fit(X_train_final_ha, y_train_bi).decision_function(X_test_final_ha)\n",
    "y_true, y_pred = y_test_bi, gbc_clf.predict(X_test_final_ha)\n",
    "\n",
    "\n",
    "gbc_pred_prob = gbc_clf.predict_proba(X_test_final_ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "gbc_fpr = dict()\n",
    "gbc_tpr = dict()\n",
    "gbc_roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    gbc_fpr[i], gbc_tpr[i], _ = roc_curve(y_test_bi[:, i], gbc_y_score[:, i])\n",
    "    gbc_roc_auc[i] = auc(gbc_fpr[i], gbc_tpr[i])\n",
    "    \n",
    "gbc_mean_roc = roc_auc_score(y_true, gbc_clf.predict_proba(X_test_final_ha), multi_class='ovr')\n",
    "gbc_mean_roc_micro = roc_auc_score(y_true, gbc_clf.predict_proba(X_test_final_ha), multi_class='ovr', average = 'micro')\n",
    "\n",
    "print(\"Dictionary of ROC_AUC score per class:\")\n",
    "print(gbc_roc_auc)\n",
    "print(\"ROC_AUC score over all three labels [Macro-averaging]:\")\n",
    "print(gbc_mean_roc)\n",
    "print(\"ROC_AUC score over all three labels with unbalanced classes taken into account [Micro-averaging]: \")\n",
    "print(gbc_mean_roc_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing macro averaging for plotting\n",
    "import numpy as np\n",
    "\n",
    "gbc_all_fpr = np.unique(np.concatenate([gbc_fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "gbc_mean_tpr = np.zeros_like(gbc_all_fpr)\n",
    "for i in range(n_classes):\n",
    "    gbc_mean_tpr += np.interp(gbc_all_fpr, gbc_fpr[i], gbc_tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "gbc_mean_tpr /= n_classes\n",
    "\n",
    "gbc_fpr[\"macro\"] = gbc_all_fpr\n",
    "gbc_tpr[\"macro\"] = gbc_mean_tpr\n",
    "gbc_roc_auc[\"macro\"] = auc(gbc_fpr[\"macro\"], gbc_tpr[\"macro\"])\n",
    "\n",
    "print(gbc_roc_auc[\"macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing micro averaging for plotting\n",
    "\n",
    "gbc_fpr[\"micro\"], gbc_tpr[\"micro\"], _ = roc_curve(y_test_bi.ravel(), gbc_y_score.ravel())\n",
    "gbc_roc_auc[\"micro\"] = auc(gbc_fpr[\"micro\"], gbc_tpr[\"micro\"])\n",
    "\n",
    "print(gbc_roc_auc[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://gist.github.com/aniruddha27/eaf96b6ce2a98eb8cded822d01493a70#file-auc-roc6-py\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(gbc_fpr[0], gbc_tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "plt.plot(gbc_fpr[1], gbc_tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "plt.plot(gbc_fpr[2], gbc_tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
    "plt.plot(gbc_fpr[\"micro\"], gbc_tpr[\"micro\"], linestyle='-',color='red', label='Micro avg ROC curve')\n",
    "plt.plot(gbc_fpr[\"macro\"], gbc_tpr[\"macro\"], linestyle='-',color='brown', label='Macro avg ROC curve' )\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# plt.savefig('Multiclass ROC',dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_final, y_train_enc)\n",
    "y_pred = knn.predict(X_test_final)\n",
    "\n",
    "\n",
    "print(knn.score(X_test_final, y_test_enc)) #mean sub-set accuracy\n",
    "print(classification_report(y_test_enc, y_pred))\n",
    "print(confusion_matrix(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tuned k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1,144,1),\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "knn_clf = GridSearchCV(\n",
    "        knn, param_grid, cv = 10, scoring='accuracy')\n",
    "\n",
    "knn_clf.fit(X_train_final, y_train_enc)\n",
    "y_true, y_pred = y_test_enc, knn_clf.predict(X_test_final)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "knn_roc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "\n",
    "print(\"Acc:\", acc)\n",
    "print(\"Accuracy:\")\n",
    "print(knn_clf.score(X_test_final, y_test_enc))\n",
    "print(\"Best parameters set found on training set:\")\n",
    "print(knn_clf.best_params_)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(knn_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(random_state=42, class_weight = 'balanced')\n",
    "svc.fit(X_train_final, y_train_enc)\n",
    "y_pred = svc.predict(X_test_final)\n",
    "\n",
    "\n",
    "print(svc.score(X_test_final, y_test_enc)) #mean sub-set accuracy\n",
    "print(classification_report(y_test_enc, y_pred))\n",
    "print(confusion_matrix(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tuned SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "param_grid = {'kernel': ['linear','rbf','poly','sigmoid'],\n",
    "              'gamma': [1, 0.1, 0.01,0.001],\n",
    "              'C': [0.1, 1, 10, 100]}\n",
    "    \n",
    "\n",
    "svc = SVC(random_state = 42, class_weight = 'balanced')\n",
    "\n",
    "svc_clf = GridSearchCV(\n",
    "        svc, param_grid, cv = 10, scoring='accuracy')\n",
    "\n",
    "svc_clf.fit(X_train_final, y_train_enc)\n",
    "y_true, y_pred = y_test_enc, svc_clf.predict(X_test_final)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "svc_roc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "\n",
    "\n",
    "print(\"Acc:\", acc)\n",
    "print(\"Mean accuracy:\")\n",
    "print(svc_clf.score(X_test_final, y_test_enc))\n",
    "print(\"Best parameters set found on training set:\")\n",
    "print(svc_clf.best_params_)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(svc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42, class_weight = 'balanced')\n",
    "rfc.fit(X_train_final, y_train_enc)\n",
    "\n",
    "\n",
    "y_pred = rfc.predict(X_test_final)\n",
    "\n",
    "\n",
    "print(rfc.score(X_test_final, y_test_enc)) #mean sub-set accuracy\n",
    "print(classification_report(y_test_enc, y_pred))\n",
    "print(confusion_matrix(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tuned RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "param_grid={'n_estimators': [50,100,200,300], #100,200,300,400,500\n",
    "            'max_features': ['log2'],\n",
    "            'max_depth': [2,3,4], #Tuning #2,3,4\n",
    "            'min_samples_split': [2],#2,3,5\n",
    "            'min_samples_leaf':[5],#1,2,5\n",
    "            'criterion': ['entropy']}#entropy\n",
    "\n",
    "# Best parameters set found on training set:\n",
    "# {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 42, verbose=2, n_jobs = -1, class_weight = 'balanced')\n",
    "\n",
    "\n",
    "rfc_clf = GridSearchCV(\n",
    "        rfc, param_grid, cv = 10, scoring='accuracy')\n",
    "\n",
    "rfc_clf.fit(X_train_final, y_train_enc)\n",
    "\n",
    "y_true, y_pred = y_test_enc, rfc_clf.predict(X_test_final)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "rfc_roc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "\n",
    "print(\"Acc:\", acc)\n",
    "print(\"Mean accuracy:\")\n",
    "print(rfc_clf.score(X_test_final, y_test_enc))\n",
    "print(\"Best parameters set found on training set:\")\n",
    "print(rfc_clf.best_params_)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(rfc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(X_train_final, y_train_enc)\n",
    "\n",
    "\n",
    "y_pred = gbc.predict(X_test_final)\n",
    "\n",
    "\n",
    "print(gbc.score(X_test_final, y_test_enc)) #mean sub-set accuracy\n",
    "print(classification_report(y_test_enc, y_pred))\n",
    "print(confusion_matrix(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tuned GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "param_grid={'n_estimators':[750],\n",
    "            'max_depth':[3], \n",
    "            'min_samples_split':[2,4,6,8,10,20,40,60],\n",
    "            'min_samples_leaf':[1,3,5,7,9],\n",
    "            'max_features':['sqrt'],\n",
    "            'subsample':[1.0],\n",
    "            'learning_rate':[0.01]}\n",
    "\n",
    "\n",
    "#optimally tuned parameters\n",
    "# param_grid={'n_estimators':[100], 'max_depth':[4], 'min_samples_split':[2],\n",
    "#            'min_samples_leaf':[10],'max_features':[7],'subsample':[1],'learning_rate':[0.005]}\n",
    "\n",
    "\n",
    "gbc=GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "\n",
    "gbc_clf = GridSearchCV(\n",
    "        gbc, param_grid, cv = 10, scoring='accuracy'\n",
    ")\n",
    "\n",
    "\n",
    "gbc_clf.fit(X_train_final, y_train_enc)\n",
    "\n",
    "y_true, y_pred = y_test_enc, gbc_clf.predict(X_test_final)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "gbc_roc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "\n",
    "\n",
    "print(\"Acc:\", acc)\n",
    "print(\"Mean accuracy:\")\n",
    "print(gbc_clf.score(X_test_final, y_test_enc))\n",
    "print(\"Best parameters set found on training set:\")\n",
    "print(gbc_clf.best_params_)\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(gbc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "\n",
    "gbc_roccurve = metrics.plot_roc_curve(gbc_clf, X_test_final, y_test_enc)\n",
    "plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "rfc_disp = metrics.plot_roc_curve(rfc_clf, X_test_final, y_test_enc, ax=ax, alpha=0.8)\n",
    "gbc_roccurve.plot(ax=ax, alpha=0.8)\n",
    "\n",
    "gbc_roc_macro = roc_auc_score(y_true, y_pred, average = 'macro')\n",
    "print(\"macro:\",gbc_roc_macro)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
